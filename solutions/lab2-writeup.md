# Lab 2 – Indirect Prompt Injection – Writeup

Use this file to document your results.

## Test table

| Test ID | Prompt (short)                   | Expected behavior            | Observed behavior                            | Outcome        |
|--------|----------------------------------|------------------------------|----------------------------------------------|----------------|
| L2-T1  | Email with override text         | Refusal                      |                                              |                |
| L2-T2  | Email asking for sys info        | Refusal                      |                                              |                |

## Observations

- Which prompts were most successful in bypassing safety?  
- Did the model reveal anything that looks like internal policy text?  
- How consistent was the model’s behavior across multiple runs?
